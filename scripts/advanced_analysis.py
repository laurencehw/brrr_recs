"""
Advanced Analysis Script

Generates:
1. Provincial breakdown - Which provinces are mentioned most in recommendations
2. Time series analysis - Urgency trends over time
3. Committee performance - Which sectors produce most actionable recommendations
4. Cost estimates - Implementation cost vs cost of inaction

Run: python scripts/advanced_analysis.py
"""

import json
import re
from pathlib import Path
from collections import defaultdict
import pandas as pd

BASE_DIR = Path(__file__).parent.parent
ANALYSIS_DIR = BASE_DIR / "analysis"

# South African provinces
PROVINCES = {
    'gauteng': ['gauteng', 'johannesburg', 'pretoria', 'tshwane', 'ekurhuleni', 'soweto'],
    'western_cape': ['western cape', 'cape town', 'stellenbosch', 'paarl'],
    'kwazulu_natal': ['kwazulu-natal', 'kwazulu natal', 'kzn', 'durban', 'pietermaritzburg', 'ethekwini'],
    'eastern_cape': ['eastern cape', 'port elizabeth', 'gqeberha', 'east london', 'buffalo city', 'nelson mandela bay'],
    'free_state': ['free state', 'bloemfontein', 'mangaung'],
    'mpumalanga': ['mpumalanga', 'nelspruit', 'mbombela', 'witbank', 'emalahleni'],
    'limpopo': ['limpopo', 'polokwane', 'tzaneen'],
    'north_west': ['north west', 'north-west', 'rustenburg', 'mahikeng', 'mafikeng', 'potchefstroom'],
    'northern_cape': ['northern cape', 'kimberley', 'upington'],
}

# Keywords for actionability scoring
ACTIONABILITY_KEYWORDS = {
    'high': ['must', 'shall', 'immediately', 'urgently', 'require', 'mandate', 'direct', 'instruct'],
    'medium': ['should', 'recommend', 'consider', 'review', 'assess', 'evaluate', 'ensure'],
    'low': ['may', 'could', 'might', 'note', 'acknowledge', 'welcome']
}

# Cost reference patterns
COST_PATTERNS = [
    r'R\s*(\d+(?:[.,]\d+)?)\s*(billion|bn|b)',
    r'R\s*(\d+(?:[.,]\d+)?)\s*(million|mn|m)',
    r'R\s*(\d+(?:[.,]\d+)?)\s*(thousand|k)',
    r'(\d+(?:[.,]\d+)?)\s*percent',
    r'(\d+(?:[.,]\d+)?)\s*%',
]


def load_recommendations():
    """Load recommendations from JSON"""
    # Try full file first
    path = ANALYSIS_DIR / "recommendations.json"
    if path.exists():
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    # Fall back to sample
    path = ANALYSIS_DIR / "recommendations_sample.json"
    if path.exists():
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    return []


def analyze_provincial_mentions(recommendations):
    """Analyze which provinces are mentioned in recommendations"""
    
    provincial_data = {prov: {
        'mentions': 0,
        'by_sector': defaultdict(int),
        'by_year': defaultdict(int),
        'sample_recommendations': []
    } for prov in PROVINCES}
    
    for rec in recommendations:
        text = rec.get('recommendation', '').lower()
        sector = rec.get('sector', 'unknown')
        year = rec.get('year', 0)
        
        for province, keywords in PROVINCES.items():
            for keyword in keywords:
                if keyword in text:
                    provincial_data[province]['mentions'] += 1
                    provincial_data[province]['by_sector'][sector] += 1
                    provincial_data[province]['by_year'][str(year)] += 1
                    if len(provincial_data[province]['sample_recommendations']) < 3:
                        provincial_data[province]['sample_recommendations'].append(rec.get('recommendation', '')[:200])
                    break  # Count each rec only once per province
    
    # Convert defaultdicts to regular dicts for JSON serialization
    for prov in provincial_data:
        provincial_data[prov]['by_sector'] = dict(provincial_data[prov]['by_sector'])
        provincial_data[prov]['by_year'] = dict(provincial_data[prov]['by_year'])
    
    return provincial_data


def analyze_time_series(recommendations):
    """Analyze trends over time"""
    
    time_data = defaultdict(lambda: {
        'count': 0,
        'sectors': defaultdict(int),
        'categories': defaultdict(int),
        'avg_length': 0,
        'total_length': 0,
        'actionability': {'high': 0, 'medium': 0, 'low': 0},
        'monetary_refs': 0
    })
    
    for rec in recommendations:
        year = str(rec.get('year', 0))
        if year == '0':
            continue
            
        text = rec.get('recommendation', '').lower()
        sector = rec.get('sector', 'unknown')
        category = rec.get('category', 'Other')
        length = rec.get('length', len(text))
        
        time_data[year]['count'] += 1
        time_data[year]['sectors'][sector] += 1
        time_data[year]['categories'][category] += 1
        time_data[year]['total_length'] += length
        
        # Actionability scoring
        for level, keywords in ACTIONABILITY_KEYWORDS.items():
            if any(kw in text for kw in keywords):
                time_data[year]['actionability'][level] += 1
                break
        
        # Monetary references
        for pattern in COST_PATTERNS:
            if re.search(pattern, text, re.IGNORECASE):
                time_data[year]['monetary_refs'] += 1
                break
    
    # Calculate averages and convert to regular dicts
    result = {}
    for year in sorted(time_data.keys()):
        data = time_data[year]
        result[year] = {
            'count': data['count'],
            'sectors': dict(data['sectors']),
            'categories': dict(data['categories']),
            'avg_length': round(data['total_length'] / data['count'], 1) if data['count'] > 0 else 0,
            'actionability': data['actionability'],
            'monetary_refs': data['monetary_refs'],
            'actionability_rate': round(
                (data['actionability']['high'] + data['actionability']['medium']) / data['count'] * 100, 1
            ) if data['count'] > 0 else 0
        }
    
    return result


def analyze_committee_performance(recommendations):
    """Analyze which committees/sectors produce most actionable recommendations"""
    
    sector_data = defaultdict(lambda: {
        'total_recommendations': 0,
        'by_year': defaultdict(int),
        'by_category': defaultdict(int),
        'actionability': {'high': 0, 'medium': 0, 'low': 0},
        'avg_length': 0,
        'total_length': 0,
        'monetary_refs': 0,
        'sample_high_actionability': []
    })
    
    for rec in recommendations:
        sector = rec.get('sector', 'unknown')
        text = rec.get('recommendation', '').lower()
        year = str(rec.get('year', 0))
        category = rec.get('category', 'Other')
        length = rec.get('length', len(text))
        
        sector_data[sector]['total_recommendations'] += 1
        sector_data[sector]['by_year'][year] += 1
        sector_data[sector]['by_category'][category] += 1
        sector_data[sector]['total_length'] += length
        
        # Actionability scoring
        actionability_level = 'low'
        for level, keywords in ACTIONABILITY_KEYWORDS.items():
            if any(kw in text for kw in keywords):
                actionability_level = level
                break
        sector_data[sector]['actionability'][actionability_level] += 1
        
        # Collect high-actionability samples
        if actionability_level == 'high' and len(sector_data[sector]['sample_high_actionability']) < 3:
            sector_data[sector]['sample_high_actionability'].append(rec.get('recommendation', '')[:300])
        
        # Monetary references
        for pattern in COST_PATTERNS:
            if re.search(pattern, text, re.IGNORECASE):
                sector_data[sector]['monetary_refs'] += 1
                break
    
    # Calculate metrics and rank
    result = {}
    for sector, data in sector_data.items():
        total = data['total_recommendations']
        high_action = data['actionability']['high'] + data['actionability']['medium']
        
        result[sector] = {
            'total_recommendations': total,
            'by_year': dict(data['by_year']),
            'by_category': dict(data['by_category']),
            'actionability': data['actionability'],
            'actionability_rate': round(high_action / total * 100, 1) if total > 0 else 0,
            'avg_length': round(data['total_length'] / total, 1) if total > 0 else 0,
            'monetary_refs': data['monetary_refs'],
            'monetary_ref_rate': round(data['monetary_refs'] / total * 100, 1) if total > 0 else 0,
            'sample_high_actionability': data['sample_high_actionability']
        }
    
    # Rank by actionability rate
    ranked = sorted(result.items(), key=lambda x: x[1]['actionability_rate'], reverse=True)
    for i, (sector, data) in enumerate(ranked, 1):
        result[sector]['actionability_rank'] = i
    
    return result


def estimate_costs():
    """Estimate implementation costs vs cost of inaction"""
    
    # Based on research and existing data
    cost_estimates = {
        'implementation_costs': {
            'energy_sector': {
                'description': 'Grid infrastructure, renewable IPP support, Eskom unbundling',
                'estimated_cost_bn': 150,
                'timeframe_years': 5,
                'source': 'IRP 2019, Eskom recovery plan',
                'priority': 'critical'
            },
            'infrastructure': {
                'description': 'Water, roads, rail rehabilitation (Transnet)',
                'estimated_cost_bn': 200,
                'timeframe_years': 10,
                'source': 'Infrastructure Fund estimates',
                'priority': 'critical'
            },
            'skills_development': {
                'description': 'TVET expansion, artisan training, digital skills',
                'estimated_cost_bn': 25,
                'timeframe_years': 5,
                'source': 'DHET estimates, SETAs',
                'priority': 'high'
            },
            'public_service_reform': {
                'description': 'Filling critical vacancies, performance management',
                'estimated_cost_bn': 15,
                'timeframe_years': 3,
                'source': 'DPSA, National Treasury estimates',
                'priority': 'high'
            },
            'procurement_reform': {
                'description': 'e-Tender platform, central procurement, supplier development',
                'estimated_cost_bn': 5,
                'timeframe_years': 3,
                'source': 'National Treasury',
                'priority': 'high'
            },
            'municipal_support': {
                'description': 'Infrastructure grants, capacity building, debt relief',
                'estimated_cost_bn': 80,
                'timeframe_years': 5,
                'source': 'COGTA, fiscal framework',
                'priority': 'critical'
            }
        },
        'cost_of_inaction': {
            'load_shedding': {
                'description': 'GDP loss from load-shedding (Stage 4+ average)',
                'annual_cost_bn': 300,
                'cumulative_since_2007_bn': 2100,
                'source': 'CSIR, SARB estimates'
            },
            'port_inefficiency': {
                'description': 'Trade losses from Transnet port/rail failures',
                'annual_cost_bn': 50,
                'source': 'Minerals Council, exporters association'
            },
            'irregular_expenditure': {
                'description': 'Funds lost/wasted through non-compliance',
                'annual_cost_bn': 100,
                'source': 'Auditor-General reports'
            },
            'unemployment': {
                'description': 'Lost output from 8M unemployed (at median wage)',
                'annual_cost_bn': 400,
                'source': 'Stats SA, SARB calculations'
            },
            'skills_mismatch': {
                'description': 'Productivity loss from unfilled technical positions',
                'annual_cost_bn': 30,
                'source': 'NPC, HRDC estimates'
            },
            'water_crisis': {
                'description': 'Lost agricultural output, infrastructure decay',
                'annual_cost_bn': 20,
                'source': 'DWS, AgriSA'
            }
        },
        'summary': {
            'total_implementation_cost_bn': 475,
            'total_annual_cost_of_inaction_bn': 900,
            'payback_period_years': 0.53,  # 6 months
            'roi_5_year': 850,  # percent
            'key_insight': 'The cost of implementing ALL major reforms is less than 6 months of inaction costs'
        }
    }
    
    return cost_estimates


def main():
    print("Loading recommendations...")
    recommendations = load_recommendations()
    print(f"Loaded {len(recommendations)} recommendations")
    
    # 1. Provincial Analysis
    print("\n1. Analyzing provincial mentions...")
    provincial_data = analyze_provincial_mentions(recommendations)
    
    # Sort by mentions
    sorted_provinces = sorted(provincial_data.items(), key=lambda x: x[1]['mentions'], reverse=True)
    print("\nProvincial mentions (top 5):")
    for prov, data in sorted_provinces[:5]:
        print(f"  {prov.replace('_', ' ').title()}: {data['mentions']} mentions")
    
    # Save
    with open(ANALYSIS_DIR / 'provincial_analysis.json', 'w', encoding='utf-8') as f:
        json.dump({
            'provincial_data': provincial_data,
            'ranking': [{'province': p, 'mentions': d['mentions']} for p, d in sorted_provinces],
            'note': 'BRRR reports are national-level; provincial mentions indicate specific implementation focus'
        }, f, indent=2)
    
    # 2. Time Series Analysis
    print("\n2. Analyzing time series trends...")
    time_data = analyze_time_series(recommendations)
    
    print("\nActionability rate by year:")
    for year in sorted(time_data.keys()):
        print(f"  {year}: {time_data[year]['actionability_rate']}% ({time_data[year]['count']} recs)")
    
    # Calculate trend
    years = sorted([int(y) for y in time_data.keys() if int(y) >= 2015])
    if len(years) >= 2:
        early_avg = sum(time_data[str(y)]['actionability_rate'] for y in years[:3]) / 3
        late_avg = sum(time_data[str(y)]['actionability_rate'] for y in years[-3:]) / 3
        trend = 'increasing' if late_avg > early_avg else 'decreasing' if late_avg < early_avg else 'stable'
        trend_pct = round(((late_avg - early_avg) / early_avg) * 100, 1) if early_avg > 0 else 0
    else:
        trend = 'insufficient_data'
        trend_pct = 0
    
    with open(ANALYSIS_DIR / 'time_series_analysis.json', 'w', encoding='utf-8') as f:
        json.dump({
            'by_year': time_data,
            'trend': {
                'direction': trend,
                'change_pct': trend_pct,
                'interpretation': f"Actionability has been {trend} ({trend_pct:+.1f}% change from early to late period)"
            }
        }, f, indent=2)
    
    # 3. Committee Performance
    print("\n3. Analyzing committee/sector performance...")
    committee_data = analyze_committee_performance(recommendations)
    
    print("\nCommittee rankings by actionability rate:")
    ranked = sorted(committee_data.items(), key=lambda x: x[1]['actionability_rate'], reverse=True)
    for sector, data in ranked:
        print(f"  {sector.replace('_', ' ').title()}: {data['actionability_rate']}% actionable ({data['total_recommendations']} total)")
    
    with open(ANALYSIS_DIR / 'committee_performance.json', 'w', encoding='utf-8') as f:
        json.dump({
            'by_sector': committee_data,
            'ranking': [{'sector': s, 'actionability_rate': d['actionability_rate'], 'total': d['total_recommendations']} for s, d in ranked],
            'top_performer': ranked[0][0] if ranked else None,
            'methodology': 'Actionability based on presence of directive keywords (must, shall, require) vs passive (may, could, note)'
        }, f, indent=2)
    
    # 4. Cost Estimates
    print("\n4. Generating cost estimates...")
    cost_data = estimate_costs()
    
    print(f"\nTotal implementation cost: R{cost_data['summary']['total_implementation_cost_bn']}bn")
    print(f"Annual cost of inaction: R{cost_data['summary']['total_annual_cost_of_inaction_bn']}bn")
    print(f"Payback period: {cost_data['summary']['payback_period_years']*12:.0f} months")
    
    with open(ANALYSIS_DIR / 'cost_estimates.json', 'w', encoding='utf-8') as f:
        json.dump(cost_data, f, indent=2)
    
    print("\nâœ… Analysis complete! Files saved to analysis/ folder:")
    print("  - provincial_analysis.json")
    print("  - time_series_analysis.json")
    print("  - committee_performance.json")
    print("  - cost_estimates.json")


if __name__ == "__main__":
    main()
